# SAMURAI ONNX ç§»æ¤æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•å°†SAMURAIé¡¹ç›®ç§»æ¤åˆ°ONNXï¼Œå®ç°é«˜æ•ˆçš„è·¨å¹³å°æ¨ç†ã€‚

## æ¦‚è¿°

SAMURAIæ˜¯åŸºäºSAM2çš„é›¶æ ·æœ¬è§†è§‰è·Ÿè¸ªç³»ç»Ÿï¼Œä¸»è¦æŒ‘æˆ˜åœ¨äºï¼š
- å¤æ‚çš„çŠ¶æ€ç®¡ç†ï¼ˆå†…å­˜é“¶è¡Œã€Kalmanæ»¤æ³¢å™¨ï¼‰
- åŠ¨æ€å½¢çŠ¶å¤„ç†
- è·¨å¸§ä¾èµ–å…³ç³»

## ç§»æ¤ç­–ç•¥

### 1. æ¨¡å—åŒ–åˆ†è§£

å°†SAMURAIåˆ†è§£ä¸ºç‹¬ç«‹çš„ONNXæ¨¡å‹ï¼š

```
SAMURAI System
â”œâ”€â”€ Image Encoder (âœ… å·²å®ç°)
â”œâ”€â”€ Prompt Encoder (ğŸ”„ éƒ¨åˆ†å®ç°)  
â”œâ”€â”€ Mask Decoder (ğŸ”„ éƒ¨åˆ†å®ç°)
â”œâ”€â”€ Memory Encoder (âŒ å¤æ‚)
â””â”€â”€ Kalman Filter (âœ… çº¯Pythonå®ç°)
```

### 2. æ ¸å¿ƒç»„ä»¶

#### å›¾åƒç¼–ç å™¨ (Image Encoder)
- **çŠ¶æ€**: âœ… å·²å®Œæˆ
- **è¾“å…¥**: `[B, 3, H, W]` å›¾åƒå¼ é‡
- **è¾“å‡º**: å¤šå°ºåº¦ç‰¹å¾å›¾
- **ONNXæ–‡ä»¶**: `image_encoder_{model_size}.onnx`

#### æç¤ºç¼–ç å™¨ (Prompt Encoder)
- **çŠ¶æ€**: ğŸ”„ åŸºç¡€å®ç°
- **è¾“å…¥**: ç‚¹åæ ‡ã€æ ‡ç­¾ã€è¾¹ç•Œæ¡†ã€æ©ç 
- **è¾“å‡º**: ç¨€ç–å’Œå¯†é›†åµŒå…¥
- **ONNXæ–‡ä»¶**: `prompt_encoder_{model_size}.onnx`

#### æ©ç è§£ç å™¨ (Mask Decoder)
- **çŠ¶æ€**: ğŸ”„ éœ€è¦ä¼˜åŒ–
- **è¾“å…¥**: å›¾åƒç‰¹å¾ + æç¤ºåµŒå…¥
- **è¾“å‡º**: æ©ç é¢„æµ‹ + IoUåˆ†æ•°
- **ONNXæ–‡ä»¶**: `mask_decoder_{model_size}.onnx`

#### Kalmanæ»¤æ³¢å™¨
- **çŠ¶æ€**: âœ… çº¯Pythonå®ç°
- **åŠŸèƒ½**: ç›®æ ‡çŠ¶æ€é¢„æµ‹å’Œæ›´æ–°
- **å®ç°**: `KalmanFilterONNX` ç±»

## ä½¿ç”¨æ–¹æ³•

### 1. å¯¼å‡ºONNXæ¨¡å‹

```bash
# å¯¼å‡ºæ‰€æœ‰ç»„ä»¶
python scripts/export_onnx.py --components all --model_name base_plus

# å¯¼å‡ºç‰¹å®šç»„ä»¶
python scripts/export_onnx.py --components image_encoder prompt_encoder --model_name base_plus

# å¯ç”¨ä¼˜åŒ–
python scripts/export_onnx.py --components all --optimize --dynamic_batch
```

### 2. ONNXæ¨ç†

```bash
# åŸºæœ¬æ¨ç†
python scripts/onnx_inference.py \
    --video_path demo.mp4 \
    --bbox "100,100,200,150" \
    --model_dir onnx_models

# GPUæ¨ç†
python scripts/onnx_inference.py \
    --video_path demo.mp4 \
    --bbox "100,100,200,150" \
    --device cuda \
    --output_video output.mp4
```

### 3. Python API

```python
from scripts.onnx_inference import SAMURAIONNXPredictor

# åˆå§‹åŒ–é¢„æµ‹å™¨
predictor = SAMURAIONNXPredictor("onnx_models", device="cpu")

# è·Ÿè¸ªè§†é¢‘
results = predictor.track_video("video.mp4", (x, y, w, h))
```

## æ€§èƒ½ä¼˜åŒ–

### 1. æ¨¡å‹ä¼˜åŒ–

```python
# å¯ç”¨ONNXä¼˜åŒ–
python scripts/export_onnx.py --optimize

# ä½¿ç”¨TensorRT (NVIDIA GPU)
import onnxruntime as ort
providers = ['TensorrtExecutionProvider', 'CUDAExecutionProvider']
session = ort.InferenceSession(model_path, providers=providers)
```

### 2. æ¨ç†ä¼˜åŒ–

- **æ‰¹å¤„ç†**: æ”¯æŒå¤šå¸§å¹¶è¡Œå¤„ç†
- **å†…å­˜ç®¡ç†**: å›ºå®šå¤§å°çš„å†…å­˜é“¶è¡Œ
- **ç²¾åº¦**: FP16æ¨ç†ï¼ˆGPUï¼‰

### 3. éƒ¨ç½²ä¼˜åŒ–

```python
# é‡åŒ–æ¨¡å‹
from onnxruntime.quantization import quantize_dynamic
quantize_dynamic(input_model, output_model)

# å›¾ä¼˜åŒ–
session_options = ort.SessionOptions()
session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
```

## é™åˆ¶å’Œè§£å†³æ–¹æ¡ˆ

### 1. å†…å­˜é“¶è¡Œæœºåˆ¶
**é—®é¢˜**: åŠ¨æ€å†…å­˜ç®¡ç†éš¾ä»¥å¯¼å‡º
**è§£å†³æ–¹æ¡ˆ**: 
- å›ºå®šå¤§å°çš„å¾ªç¯ç¼“å†²åŒº
- ç®€åŒ–çš„å†…å­˜æ›´æ–°ç­–ç•¥

### 2. Flash Attention
**é—®é¢˜**: å¯èƒ½ä¸å®Œå…¨å…¼å®¹ONNX
**è§£å†³æ–¹æ¡ˆ**:
- å›é€€åˆ°æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶
- ä½¿ç”¨ONNXå…¼å®¹çš„æ³¨æ„åŠ›å®ç°

### 3. åŠ¨æ€å½¢çŠ¶
**é—®é¢˜**: ä¸åŒè§†é¢‘åˆ†è¾¨ç‡
**è§£å†³æ–¹æ¡ˆ**:
- å›ºå®šè¾“å…¥å°ºå¯¸ + é¢„å¤„ç†
- åŠ¨æ€è½´é…ç½®

## æµ‹è¯•å’ŒéªŒè¯

### 1. ç²¾åº¦éªŒè¯

```bash
# æ¯”è¾ƒPyTorch vs ONNXç»“æœ
python scripts/validate_onnx.py \
    --pytorch_model configs/samurai/sam2.1_hiera_b+.yaml \
    --onnx_models onnx_models \
    --test_video test.mp4
```

### 2. æ€§èƒ½åŸºå‡†

```bash
# æ€§èƒ½æµ‹è¯•
python scripts/benchmark_onnx.py \
    --model_dir onnx_models \
    --device cuda \
    --batch_sizes 1,4,8
```

## ä¾èµ–å®‰è£…

```bash
# åŸºç¡€ä¾èµ–
pip install onnxruntime opencv-python numpy

# GPUæ”¯æŒ
pip install onnxruntime-gpu

# ä¼˜åŒ–å·¥å…·
pip install onnx onnxoptimizer

# TensorRT (å¯é€‰)
pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/
```

## æ–‡ä»¶ç»“æ„

```
samurai/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ export_onnx.py          # ONNXå¯¼å‡ºè„šæœ¬
â”‚   â”œâ”€â”€ onnx_inference.py       # ONNXæ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ validate_onnx.py        # ç²¾åº¦éªŒè¯ (å¾…å®ç°)
â”‚   â””â”€â”€ benchmark_onnx.py       # æ€§èƒ½æµ‹è¯• (å¾…å®ç°)
â”œâ”€â”€ onnx_models/                # å¯¼å‡ºçš„ONNXæ¨¡å‹
â”‚   â”œâ”€â”€ image_encoder_base_plus.onnx
â”‚   â”œâ”€â”€ prompt_encoder_base_plus.onnx
â”‚   â””â”€â”€ mask_decoder_base_plus.onnx
â””â”€â”€ ONNX_MIGRATION_GUIDE.md     # æœ¬æŒ‡å—
```

## ä¸‹ä¸€æ­¥è®¡åˆ’

1. **å®Œå–„æ©ç è§£ç å™¨å¯¼å‡º** - è§£å†³å¤æ‚è¾“å…¥è¾“å‡ºç»“æ„
2. **å®ç°å†…å­˜ç¼–ç å™¨** - è®¾è®¡çŠ¶æ€æ— å…³çš„ç‰ˆæœ¬
3. **ç«¯åˆ°ç«¯ä¼˜åŒ–** - æ•´åˆæ‰€æœ‰ç»„ä»¶
4. **ç§»åŠ¨ç«¯éƒ¨ç½²** - ONNX.js æˆ– NCNN æ”¯æŒ
5. **é‡åŒ–å’Œå‹ç¼©** - å‡å°‘æ¨¡å‹å¤§å°

## å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆä¸å¯¼å‡ºå®Œæ•´æ¨¡å‹ï¼Ÿ
A: SAMURAIåŒ…å«å¤æ‚çš„çŠ¶æ€ç®¡ç†å’Œè·¨å¸§ä¾èµ–ï¼Œåˆ†æ¨¡å—å¯¼å‡ºæ›´çµæ´»ä¸”æ˜“äºä¼˜åŒ–ã€‚

### Q: æ€§èƒ½æå‡å¦‚ä½•ï¼Ÿ
A: é¢„æœŸCPUæ¨ç†æå‡2-3å€ï¼ŒGPUæ¨ç†æå‡1.5-2å€ï¼ˆå–å†³äºç¡¬ä»¶ï¼‰ã€‚

### Q: ç²¾åº¦æŸå¤±å¤šå°‘ï¼Ÿ
A: ç†è®ºä¸Šæ— æŸå¤±ï¼Œå®é™…å¯èƒ½æœ‰å¾®å°å·®å¼‚ï¼ˆ<1% mAPï¼‰ã€‚

### Q: æ”¯æŒå“ªäº›å¹³å°ï¼Ÿ
A: Windowsã€Linuxã€macOSï¼Œä»¥åŠç§»åŠ¨ç«¯ï¼ˆé€šè¿‡ONNX.jsæˆ–ä¸“ç”¨è¿è¡Œæ—¶ï¼‰ã€‚

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPRæ¥æ”¹è¿›ONNXç§»æ¤ï¼š
- æ€§èƒ½ä¼˜åŒ–å»ºè®®
- æ–°å¹³å°æ”¯æŒ
- Bugä¿®å¤
- æ–‡æ¡£æ”¹è¿›

## è®¸å¯è¯

éµå¾ªåŸSAMURAIé¡¹ç›®çš„è®¸å¯è¯æ¡æ¬¾ã€‚

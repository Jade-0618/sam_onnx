"""
ç®€åŒ–çš„ç«¯åˆ°ç«¯æ¨¡å‹å¯¼å‡º
é¿å…å¤æ‚ä¾èµ–ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰çš„å›¾åƒç¼–ç å™¨åˆ›å»ºç«¯åˆ°ç«¯æ¨¡å‹
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np
import onnxruntime as ort

def create_mock_end_to_end_model():
    """åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„ç«¯åˆ°ç«¯æ¨¡å‹ç”¨äºæµ‹è¯•"""
    
    print("ğŸ”§ åˆ›å»ºæ¨¡æ‹Ÿç«¯åˆ°ç«¯æ¨¡å‹")
    print("=" * 30)
    
    class MockSAMURAIEndToEnd(nn.Module):
        """æ¨¡æ‹Ÿçš„SAMURAIç«¯åˆ°ç«¯æ¨¡å‹"""
        
        def __init__(self):
            super().__init__()
            
            # æ¨¡æ‹Ÿå›¾åƒç¼–ç å™¨ - ç®€åŒ–ç‰ˆæœ¬
            self.image_encoder = nn.Sequential(
                nn.Conv2d(3, 64, 7, stride=2, padding=3),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(64, 128, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(128, 256, 3, padding=1),
                nn.ReLU(),
                nn.AdaptiveAvgPool2d((64, 64))
            )
            
            # æ¨¡æ‹Ÿæç¤ºç¼–ç å™¨
            self.point_embed = nn.Embedding(2, 256)  # æ­£è´Ÿç‚¹åµŒå…¥
            self.box_embed = nn.Linear(4, 256)
            
            # æ¨¡æ‹Ÿæ©ç è§£ç å™¨
            self.mask_decoder = nn.Sequential(
                nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
                nn.ReLU(),
                nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
                nn.ReLU(),
                nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),
                nn.ReLU(),
                nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),  # 3ä¸ªæ©ç 
                nn.Sigmoid()
            )
            
            # IoUé¢„æµ‹å¤´
            self.iou_head = nn.Sequential(
                nn.AdaptiveAvgPool2d(1),
                nn.Flatten(),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Linear(128, 3)  # 3ä¸ªæ©ç çš„IoU
            )
            
            # å†…å­˜ç¼–ç å™¨ - ç®€åŒ–ç‰ˆæœ¬
            self.memory_encoder = nn.Sequential(
                nn.Conv2d(256, 256, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(256, 256, 3, padding=1)
            )
            
        def forward(self, image, point_coords, point_labels, box_coords):
            """
            å‰å‘ä¼ æ’­
            
            Args:
                image: [B, 3, H, W] è¾“å…¥å›¾åƒ
                point_coords: [B, N, 2] ç‚¹åæ ‡
                point_labels: [B, N] ç‚¹æ ‡ç­¾
                box_coords: [B, 4] è¾¹ç•Œæ¡†åæ ‡
                
            Returns:
                masks: [B, 3, H, W] é¢„æµ‹æ©ç 
                iou_predictions: [B, 3] IoUé¢„æµ‹
                memory_features: [B, 256, 64, 64] å†…å­˜ç‰¹å¾
            """
            batch_size = image.shape[0]
            
            # 1. å›¾åƒç¼–ç 
            image_features = self.image_encoder(image)  # [B, 256, 64, 64]
            
            # 2. æç¤ºç¼–ç  (ç®€åŒ–)
            # ç‚¹æç¤º
            point_embeds = self.point_embed(point_labels.long())  # [B, N, 256]
            point_embeds = point_embeds.mean(dim=1, keepdim=True)  # [B, 1, 256]
            
            # æ¡†æç¤º
            box_embeds = self.box_embed(box_coords)  # [B, 256]
            box_embeds = box_embeds.unsqueeze(1)  # [B, 1, 256]
            
            # åˆå¹¶æç¤º
            prompt_embeds = (point_embeds + box_embeds).squeeze(1)  # [B, 256]
            
            # 3. ç‰¹å¾èåˆ
            prompt_embeds = prompt_embeds.unsqueeze(-1).unsqueeze(-1)  # [B, 256, 1, 1]
            prompt_embeds = prompt_embeds.expand(-1, -1, 64, 64)  # [B, 256, 64, 64]
            
            fused_features = image_features + prompt_embeds
            
            # 4. æ©ç è§£ç 
            masks = self.mask_decoder(fused_features)  # [B, 3, 1024, 1024]
            
            # 5. IoUé¢„æµ‹
            iou_predictions = self.iou_head(fused_features)  # [B, 3]
            iou_predictions = torch.sigmoid(iou_predictions)
            
            # 6. å†…å­˜ç¼–ç 
            memory_features = self.memory_encoder(fused_features)  # [B, 256, 64, 64]
            
            return masks, iou_predictions, memory_features
    
    return MockSAMURAIEndToEnd()

def export_mock_end_to_end():
    """å¯¼å‡ºæ¨¡æ‹Ÿçš„ç«¯åˆ°ç«¯æ¨¡å‹"""
    
    print("ğŸš€ å¯¼å‡ºæ¨¡æ‹Ÿç«¯åˆ°ç«¯SAMURAIæ¨¡å‹")
    print("=" * 50)
    
    # åˆ›å»ºæ¨¡å‹
    model = create_mock_end_to_end_model()
    model.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 1
    image_size = 1024
    
    image = torch.randn(batch_size, 3, image_size, image_size, dtype=torch.float32)
    point_coords = torch.tensor([[[512.0, 512.0]]], dtype=torch.float32)
    point_labels = torch.tensor([[1]], dtype=torch.int64)
    box_coords = torch.tensor([[100.0, 100.0, 400.0, 400.0]], dtype=torch.float32)
    
    print(f"æµ‹è¯•è¾“å…¥:")
    print(f"  å›¾åƒ: {image.shape}")
    print(f"  ç‚¹åæ ‡: {point_coords.shape}")
    print(f"  ç‚¹æ ‡ç­¾: {point_labels.shape}")
    print(f"  è¾¹ç•Œæ¡†: {box_coords.shape}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    with torch.no_grad():
        try:
            masks, iou_predictions, memory_features = model(
                image, point_coords, point_labels, box_coords
            )
            print(f"\nè¾“å‡º:")
            print(f"  æ©ç : {masks.shape}")
            print(f"  IoUé¢„æµ‹: {iou_predictions.shape}")
            print(f"  å†…å­˜ç‰¹å¾: {memory_features.shape}")
            
        except Exception as e:
            print(f"å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    # å¯¼å‡ºONNX
    output_dir = "onnx_models"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "samurai_mock_end_to_end.onnx")
    
    print(f"\nå¯¼å‡ºåˆ°: {output_path}")
    
    try:
        torch.onnx.export(
            model,
            (image, point_coords, point_labels, box_coords),
            output_path,
            input_names=["image", "point_coords", "point_labels", "box_coords"],
            output_names=["masks", "iou_predictions", "memory_features"],
            opset_version=17,
            do_constant_folding=True,
            export_params=True,
            verbose=True
        )
        
        print("âœ… æ¨¡æ‹Ÿç«¯åˆ°ç«¯æ¨¡å‹å¯¼å‡ºæˆåŠŸ!")
        
        # éªŒè¯å¯¼å‡ºçš„æ¨¡å‹
        try:
            session = ort.InferenceSession(output_path)
            
            # æµ‹è¯•ONNXæ¨¡å‹
            onnx_inputs = {
                "image": image.numpy(),
                "point_coords": point_coords.numpy(),
                "point_labels": point_labels.numpy(),
                "box_coords": box_coords.numpy()
            }
            
            onnx_outputs = session.run(None, onnx_inputs)
            
            print(f"\nONNXéªŒè¯:")
            print(f"  ONNXæ©ç : {onnx_outputs[0].shape}")
            print(f"  ONNX IoU: {onnx_outputs[1].shape}")
            print(f"  ONNXå†…å­˜ç‰¹å¾: {onnx_outputs[2].shape}")
            
            # æ¯”è¾ƒè¾“å‡ºå·®å¼‚
            mask_diff = np.mean(np.abs(masks.numpy() - onnx_outputs[0]))
            iou_diff = np.mean(np.abs(iou_predictions.numpy() - onnx_outputs[1]))
            memory_diff = np.mean(np.abs(memory_features.numpy() - onnx_outputs[2]))
            
            print(f"  æ©ç å·®å¼‚: {mask_diff:.6f}")
            print(f"  IoUå·®å¼‚: {iou_diff:.6f}")
            print(f"  å†…å­˜ç‰¹å¾å·®å¼‚: {memory_diff:.6f}")
            
            if mask_diff < 1e-5 and iou_diff < 1e-5 and memory_diff < 1e-5:
                print("âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡!")
            else:
                print("âš ï¸  ONNXæ¨¡å‹å­˜åœ¨ç²¾åº¦å·®å¼‚")
                
        except Exception as e:
            print(f"ONNXéªŒè¯å¤±è´¥: {e}")
            
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_lightweight_end_to_end():
    """åˆ›å»ºè½»é‡çº§ç«¯åˆ°ç«¯æ¨¡å‹"""
    
    print("\nğŸª¶ åˆ›å»ºè½»é‡çº§ç«¯åˆ°ç«¯æ¨¡å‹")
    print("=" * 40)
    
    class LightweightSAMURAI(nn.Module):
        """è½»é‡çº§SAMURAIæ¨¡å‹"""
        
        def __init__(self):
            super().__init__()
            
            # è½»é‡çº§å›¾åƒç¼–ç å™¨
            self.image_encoder = nn.Sequential(
                nn.Conv2d(3, 32, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(4),  # 1024 -> 256
                nn.Conv2d(32, 64, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(4),  # 256 -> 64
                nn.Conv2d(64, 128, 3, padding=1),
                nn.ReLU()
            )
            
            # ç®€å•çš„æ©ç è§£ç å™¨
            self.mask_decoder = nn.Sequential(
                nn.ConvTranspose2d(128, 64, 4, stride=4, padding=0),  # 64 -> 256
                nn.ReLU(),
                nn.ConvTranspose2d(64, 32, 4, stride=4, padding=0),   # 256 -> 1024
                nn.ReLU(),
                nn.Conv2d(32, 1, 3, padding=1),  # å•æ©ç è¾“å‡º
                nn.Sigmoid()
            )
            
            # IoUé¢„æµ‹
            self.iou_head = nn.Sequential(
                nn.AdaptiveAvgPool2d(1),
                nn.Flatten(),
                nn.Linear(128, 1),
                nn.Sigmoid()
            )
            
        def forward(self, image, point_coords, point_labels, box_coords):
            """è½»é‡çº§å‰å‘ä¼ æ’­"""
            
            # å›¾åƒç¼–ç 
            features = self.image_encoder(image)  # [B, 128, 64, 64]
            
            # æ©ç è§£ç 
            mask = self.mask_decoder(features)  # [B, 1, 1024, 1024]
            
            # IoUé¢„æµ‹
            iou = self.iou_head(features)  # [B, 1]
            
            # å†…å­˜ç‰¹å¾å°±æ˜¯ç¼–ç ç‰¹å¾
            memory_features = features  # [B, 128, 64, 64]
            
            return mask, iou, memory_features
    
    return LightweightSAMURAI()

def export_lightweight_model():
    """å¯¼å‡ºè½»é‡çº§æ¨¡å‹"""
    
    model = create_lightweight_end_to_end()
    model.eval()
    
    # æµ‹è¯•è¾“å…¥
    image = torch.randn(1, 3, 1024, 1024, dtype=torch.float32)
    point_coords = torch.tensor([[[512.0, 512.0]]], dtype=torch.float32)
    point_labels = torch.tensor([[1]], dtype=torch.int64)
    box_coords = torch.tensor([[100.0, 100.0, 400.0, 400.0]], dtype=torch.float32)
    
    print(f"è½»é‡çº§æ¨¡å‹è¾“å…¥:")
    print(f"  å›¾åƒ: {image.shape}")
    
    # æµ‹è¯•
    with torch.no_grad():
        mask, iou, memory_features = model(image, point_coords, point_labels, box_coords)
        print(f"  æ©ç : {mask.shape}")
        print(f"  IoU: {iou.shape}")
        print(f"  å†…å­˜ç‰¹å¾: {memory_features.shape}")
    
    # å¯¼å‡º
    output_path = os.path.join("onnx_models", "samurai_lightweight.onnx")
    
    try:
        torch.onnx.export(
            model,
            (image, point_coords, point_labels, box_coords),
            output_path,
            input_names=["image", "point_coords", "point_labels", "box_coords"],
            output_names=["mask", "iou", "memory_features"],
            opset_version=17,
            do_constant_folding=True,
            export_params=True,
            verbose=False
        )
        
        print(f"âœ… è½»é‡çº§æ¨¡å‹å¯¼å‡ºæˆåŠŸ: {output_path}")
        
        # æ£€æŸ¥æ¨¡å‹å¤§å°
        model_size = os.path.getsize(output_path) / (1024 * 1024)
        print(f"   æ¨¡å‹å¤§å°: {model_size:.2f} MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ è½»é‡çº§æ¨¡å‹å¯¼å‡ºå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç®€åŒ–ç«¯åˆ°ç«¯SAMURAIæ¨¡å‹å¯¼å‡º")
    print("=" * 50)
    
    success1 = export_mock_end_to_end()
    success2 = export_lightweight_model()
    
    print("\n" + "=" * 50)
    print("ğŸ† å¯¼å‡ºæ€»ç»“")
    
    if success1:
        print("âœ… æ¨¡æ‹Ÿç«¯åˆ°ç«¯æ¨¡å‹: onnx_models/samurai_mock_end_to_end.onnx")
    else:
        print("âŒ æ¨¡æ‹Ÿç«¯åˆ°ç«¯æ¨¡å‹å¯¼å‡ºå¤±è´¥")
    
    if success2:
        print("âœ… è½»é‡çº§æ¨¡å‹: onnx_models/samurai_lightweight.onnx")
    else:
        print("âŒ è½»é‡çº§æ¨¡å‹å¯¼å‡ºå¤±è´¥")
    
    if success1 or success2:
        print("\nğŸ‰ è‡³å°‘ä¸€ä¸ªç«¯åˆ°ç«¯æ¨¡å‹å¯¼å‡ºæˆåŠŸ!")
        print("ğŸ’¡ è¿™äº›æ¨¡å‹å¯ä»¥ç”¨äºæµ‹è¯•ç«¯åˆ°ç«¯æ¨ç†æµç¨‹")
        print("ğŸ’¡ è™½ç„¶æ˜¯æ¨¡æ‹Ÿæ¨¡å‹ï¼Œä½†å…·æœ‰å®Œæ•´çš„è¾“å…¥è¾“å‡ºæ¥å£")
    else:
        print("\nâŒ æ‰€æœ‰å¯¼å‡ºéƒ½å¤±è´¥äº†")

if __name__ == "__main__":
    main()

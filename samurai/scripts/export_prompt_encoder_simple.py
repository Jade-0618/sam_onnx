"""
ç®€åŒ–çš„æç¤ºç¼–ç å™¨ONNXå¯¼å‡º
ä¸“é—¨å¤„ç†æç¤ºç¼–ç å™¨çš„å¤æ‚è¾“å…¥ç»“æ„
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sam2_path = os.path.join(project_root, "sam2")
sys.path.insert(0, sam2_path)

from sam2.build_sam import build_sam2_video_predictor

class SimplePromptEncoder(nn.Module):
    """
    ç®€åŒ–çš„æç¤ºç¼–ç å™¨ï¼Œä¸“é—¨ç”¨äºONNXå¯¼å‡º
    å°†å¤æ‚çš„å¯é€‰è¾“å…¥ç®€åŒ–ä¸ºå›ºå®šè¾“å…¥
    """
    
    def __init__(self, original_encoder):
        super().__init__()
        self.original_encoder = original_encoder
        
    def forward(self, point_coords, point_labels, box_coords):
        """
        ç®€åŒ–çš„å‰å‘ä¼ æ’­
        
        Args:
            point_coords: [B, N, 2] ç‚¹åæ ‡
            point_labels: [B, N] ç‚¹æ ‡ç­¾ (0=è´Ÿç‚¹, 1=æ­£ç‚¹)
            box_coords: [B, 4] è¾¹ç•Œæ¡†åæ ‡ [x1, y1, x2, y2]
        
        Returns:
            sparse_embeddings: [B, N+2, C] ç¨€ç–åµŒå…¥ (ç‚¹+æ¡†è§’ç‚¹)
            dense_embeddings: [B, C, H, W] å¯†é›†åµŒå…¥
        """
        # å¤„ç†ç‚¹æç¤º
        points = (point_coords, point_labels)
        
        # å¤„ç†æ¡†æç¤º
        boxes = box_coords
        
        # ä¸ä½¿ç”¨æ©ç æç¤º
        masks = None
        
        # è°ƒç”¨åŸå§‹ç¼–ç å™¨
        sparse_embeddings, dense_embeddings = self.original_encoder(
            points=points,
            boxes=boxes, 
            masks=masks
        )
        
        return sparse_embeddings, dense_embeddings

def export_simple_prompt_encoder():
    """å¯¼å‡ºç®€åŒ–çš„æç¤ºç¼–ç å™¨"""
    
    print("ğŸ”§ å¯¼å‡ºç®€åŒ–æç¤ºç¼–ç å™¨")
    print("=" * 40)
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(project_root, "sam2/checkpoints/sam2.1_hiera_base_plus.pt")
    config_path = os.path.join(project_root, "sam2/sam2/configs/samurai/sam2.1_hiera_b+.yaml")
    
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    predictor = build_sam2_video_predictor(config_path, model_path, device="cpu")
    predictor.eval()
    
    # åˆ›å»ºç®€åŒ–ç¼–ç å™¨
    simple_encoder = SimplePromptEncoder(predictor.sam_prompt_encoder)
    simple_encoder.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 1
    num_points = 3  # å‡å°‘ç‚¹æ•°é‡ä»¥ç®€åŒ–
    
    # ç‚¹åæ ‡ (å½’ä¸€åŒ–åˆ°0-1024)
    point_coords = torch.tensor([[[100.0, 200.0], [300.0, 400.0], [500.0, 600.0]]], dtype=torch.float32)
    
    # ç‚¹æ ‡ç­¾ (1=æ­£ç‚¹, 0=è´Ÿç‚¹)
    point_labels = torch.tensor([[1, 1, 0]], dtype=torch.int64)
    
    # è¾¹ç•Œæ¡† [x1, y1, x2, y2]
    box_coords = torch.tensor([[50.0, 50.0, 200.0, 200.0]], dtype=torch.float32)
    
    print(f"æµ‹è¯•è¾“å…¥:")
    print(f"  ç‚¹åæ ‡: {point_coords.shape} = {point_coords}")
    print(f"  ç‚¹æ ‡ç­¾: {point_labels.shape} = {point_labels}")
    print(f"  è¾¹ç•Œæ¡†: {box_coords.shape} = {box_coords}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    with torch.no_grad():
        sparse_emb, dense_emb = simple_encoder(point_coords, point_labels, box_coords)
        print(f"\nè¾“å‡º:")
        print(f"  ç¨€ç–åµŒå…¥: {sparse_emb.shape}")
        print(f"  å¯†é›†åµŒå…¥: {dense_emb.shape}")
    
    # å¯¼å‡ºONNX
    output_dir = "onnx_models"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "prompt_encoder_simple.onnx")
    
    print(f"\nå¯¼å‡ºåˆ°: {output_path}")
    
    try:
        torch.onnx.export(
            simple_encoder,
            (point_coords, point_labels, box_coords),
            output_path,
            input_names=["point_coords", "point_labels", "box_coords"],
            output_names=["sparse_embeddings", "dense_embeddings"],
            opset_version=17,
            do_constant_folding=True,
            export_params=True,
            verbose=True
        )
        
        print("âœ… æç¤ºç¼–ç å™¨å¯¼å‡ºæˆåŠŸ!")
        
        # éªŒè¯å¯¼å‡ºçš„æ¨¡å‹
        import onnxruntime as ort
        session = ort.InferenceSession(output_path)
        
        # æµ‹è¯•ONNXæ¨¡å‹
        onnx_inputs = {
            "point_coords": point_coords.numpy(),
            "point_labels": point_labels.numpy(),
            "box_coords": box_coords.numpy()
        }
        
        onnx_outputs = session.run(None, onnx_inputs)
        
        print(f"\nONNXéªŒè¯:")
        print(f"  ONNXç¨€ç–åµŒå…¥: {onnx_outputs[0].shape}")
        print(f"  ONNXå¯†é›†åµŒå…¥: {onnx_outputs[1].shape}")
        
        # æ¯”è¾ƒè¾“å‡ºå·®å¼‚
        sparse_diff = np.mean(np.abs(sparse_emb.numpy() - onnx_outputs[0]))
        dense_diff = np.mean(np.abs(dense_emb.numpy() - onnx_outputs[1]))
        
        print(f"  ç¨€ç–åµŒå…¥å·®å¼‚: {sparse_diff:.6f}")
        print(f"  å¯†é›†åµŒå…¥å·®å¼‚: {dense_diff:.6f}")
        
        if sparse_diff < 1e-5 and dense_diff < 1e-5:
            print("âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡!")
        else:
            print("âš ï¸  ONNXæ¨¡å‹å­˜åœ¨ç²¾åº¦å·®å¼‚")
            
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

class PointOnlyPromptEncoder(nn.Module):
    """
    ä»…æ”¯æŒç‚¹æç¤ºçš„ç¼–ç å™¨ - æœ€ç®€åŒ–ç‰ˆæœ¬
    """
    
    def __init__(self, original_encoder):
        super().__init__()
        self.original_encoder = original_encoder
        
    def forward(self, point_coords, point_labels):
        """
        ä»…å¤„ç†ç‚¹æç¤º
        
        Args:
            point_coords: [B, N, 2] ç‚¹åæ ‡
            point_labels: [B, N] ç‚¹æ ‡ç­¾
        """
        points = (point_coords, point_labels)
        
        sparse_embeddings, dense_embeddings = self.original_encoder(
            points=points,
            boxes=None,
            masks=None
        )
        
        return sparse_embeddings, dense_embeddings

def export_point_only_encoder():
    """å¯¼å‡ºä»…æ”¯æŒç‚¹çš„ç¼–ç å™¨"""
    
    print("\nğŸ¯ å¯¼å‡ºç‚¹æç¤ºç¼–ç å™¨")
    print("=" * 30)
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(project_root, "sam2/checkpoints/sam2.1_hiera_base_plus.pt")
    config_path = os.path.join(project_root, "sam2/sam2/configs/samurai/sam2.1_hiera_b+.yaml")
    
    predictor = build_sam2_video_predictor(config_path, model_path, device="cpu")
    predictor.eval()
    
    # åˆ›å»ºç‚¹ç¼–ç å™¨
    point_encoder = PointOnlyPromptEncoder(predictor.sam_prompt_encoder)
    point_encoder.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    point_coords = torch.tensor([[[512.0, 512.0], [256.0, 256.0]]], dtype=torch.float32)
    point_labels = torch.tensor([[1, 0]], dtype=torch.int64)
    
    print(f"ç‚¹ç¼–ç å™¨è¾“å…¥:")
    print(f"  ç‚¹åæ ‡: {point_coords.shape}")
    print(f"  ç‚¹æ ‡ç­¾: {point_labels.shape}")
    
    # æµ‹è¯•
    with torch.no_grad():
        sparse_emb, dense_emb = point_encoder(point_coords, point_labels)
        print(f"  ç¨€ç–åµŒå…¥: {sparse_emb.shape}")
        print(f"  å¯†é›†åµŒå…¥: {dense_emb.shape}")
    
    # å¯¼å‡º
    output_path = os.path.join("onnx_models", "prompt_encoder_points_only.onnx")
    
    try:
        torch.onnx.export(
            point_encoder,
            (point_coords, point_labels),
            output_path,
            input_names=["point_coords", "point_labels"],
            output_names=["sparse_embeddings", "dense_embeddings"],
            opset_version=17,
            do_constant_folding=True,
            export_params=True,
            verbose=False
        )
        
        print(f"âœ… ç‚¹ç¼–ç å™¨å¯¼å‡ºæˆåŠŸ: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ç‚¹ç¼–ç å™¨å¯¼å‡ºå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ SAMURAI æç¤ºç¼–ç å™¨ ONNX å¯¼å‡º")
    print("=" * 50)
    
    success1 = export_simple_prompt_encoder()
    success2 = export_point_only_encoder()
    
    print("\n" + "=" * 50)
    if success1 or success2:
        print("ğŸ‰ è‡³å°‘ä¸€ä¸ªæç¤ºç¼–ç å™¨å¯¼å‡ºæˆåŠŸ!")
        
        if success1:
            print("âœ… å®Œæ•´æç¤ºç¼–ç å™¨: onnx_models/prompt_encoder_simple.onnx")
        if success2:
            print("âœ… ç‚¹æç¤ºç¼–ç å™¨: onnx_models/prompt_encoder_points_only.onnx")
    else:
        print("âŒ æ‰€æœ‰å¯¼å‡ºéƒ½å¤±è´¥äº†")

if __name__ == "__main__":
    main()

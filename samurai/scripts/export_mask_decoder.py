"""
æ©ç è§£ç å™¨ONNXå¯¼å‡º
å¤„ç†SAM2æ©ç è§£ç å™¨çš„å¤æ‚è¾“å…¥è¾“å‡ºç»“æ„
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sam2_path = os.path.join(project_root, "sam2")
sys.path.insert(0, sam2_path)

from sam2.build_sam import build_sam2_video_predictor

class SimpleMaskDecoder(nn.Module):
    """
    ç®€åŒ–çš„æ©ç è§£ç å™¨ï¼Œç”¨äºONNXå¯¼å‡º
    """
    
    def __init__(self, original_decoder, prompt_encoder):
        super().__init__()
        self.original_decoder = original_decoder
        self.prompt_encoder = prompt_encoder
        
    def forward(self, image_embeddings, sparse_prompt_embeddings, dense_prompt_embeddings):
        """
        ç®€åŒ–çš„æ©ç è§£ç å™¨å‰å‘ä¼ æ’­
        
        Args:
            image_embeddings: [B, C, H, W] å›¾åƒç‰¹å¾
            sparse_prompt_embeddings: [B, N, C] ç¨€ç–æç¤ºåµŒå…¥
            dense_prompt_embeddings: [B, C, H, W] å¯†é›†æç¤ºåµŒå…¥
            
        Returns:
            masks: [B, num_masks, H, W] é¢„æµ‹æ©ç 
            iou_predictions: [B, num_masks] IoUé¢„æµ‹
        """
        # è·å–ä½ç½®ç¼–ç 
        image_pe = self.prompt_encoder.get_dense_pe()
        
        # è°ƒç”¨åŸå§‹è§£ç å™¨
        masks, iou_predictions, _, _ = self.original_decoder(
            image_embeddings=image_embeddings,
            image_pe=image_pe,
            sparse_prompt_embeddings=sparse_prompt_embeddings,
            dense_prompt_embeddings=dense_prompt_embeddings,
            multimask_output=True,
            repeat_image=False,
            high_res_features=None
        )
        
        return masks, iou_predictions

def export_mask_decoder():
    """å¯¼å‡ºæ©ç è§£ç å™¨"""
    
    print("ğŸ­ å¯¼å‡ºæ©ç è§£ç å™¨")
    print("=" * 30)
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(project_root, "sam2/checkpoints/sam2.1_hiera_base_plus.pt")
    config_path = os.path.join(project_root, "sam2/sam2/configs/samurai/sam2.1_hiera_b+.yaml")
    
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    predictor = build_sam2_video_predictor(config_path, model_path, device="cpu")
    predictor.eval()
    
    # åˆ›å»ºç®€åŒ–è§£ç å™¨
    simple_decoder = SimpleMaskDecoder(predictor.sam_mask_decoder, predictor.sam_prompt_encoder)
    simple_decoder.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 1
    embed_dim = 256
    
    # å›¾åƒåµŒå…¥ (æ¥è‡ªå›¾åƒç¼–ç å™¨çš„è¾“å‡º)
    image_embeddings = torch.randn(batch_size, embed_dim, 64, 64, dtype=torch.float32)
    
    # ç¨€ç–æç¤ºåµŒå…¥ (æ¥è‡ªæç¤ºç¼–ç å™¨)
    num_sparse_prompts = 5  # 3ä¸ªç‚¹ + 2ä¸ªæ¡†è§’ç‚¹
    sparse_prompt_embeddings = torch.randn(batch_size, num_sparse_prompts, embed_dim, dtype=torch.float32)
    
    # å¯†é›†æç¤ºåµŒå…¥ (æ¥è‡ªæç¤ºç¼–ç å™¨)
    dense_prompt_embeddings = torch.randn(batch_size, embed_dim, 64, 64, dtype=torch.float32)
    
    print(f"æµ‹è¯•è¾“å…¥:")
    print(f"  å›¾åƒåµŒå…¥: {image_embeddings.shape}")
    print(f"  ç¨€ç–æç¤ºåµŒå…¥: {sparse_prompt_embeddings.shape}")
    print(f"  å¯†é›†æç¤ºåµŒå…¥: {dense_prompt_embeddings.shape}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    with torch.no_grad():
        try:
            masks, iou_predictions = simple_decoder(
                image_embeddings, sparse_prompt_embeddings, dense_prompt_embeddings
            )
            print(f"\nè¾“å‡º:")
            print(f"  æ©ç : {masks.shape}")
            print(f"  IoUé¢„æµ‹: {iou_predictions.shape}")
            
        except Exception as e:
            print(f"å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    # å¯¼å‡ºONNX
    output_dir = "onnx_models"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "mask_decoder_simple.onnx")
    
    print(f"\nå¯¼å‡ºåˆ°: {output_path}")
    
    try:
        torch.onnx.export(
            simple_decoder,
            (image_embeddings, sparse_prompt_embeddings, dense_prompt_embeddings),
            output_path,
            input_names=["image_embeddings", "sparse_prompt_embeddings", "dense_prompt_embeddings"],
            output_names=["masks", "iou_predictions"],
            opset_version=17,
            do_constant_folding=True,
            export_params=True,
            verbose=True
        )
        
        print("âœ… æ©ç è§£ç å™¨å¯¼å‡ºæˆåŠŸ!")
        
        # éªŒè¯å¯¼å‡ºçš„æ¨¡å‹
        import onnxruntime as ort
        session = ort.InferenceSession(output_path)
        
        # æµ‹è¯•ONNXæ¨¡å‹
        onnx_inputs = {
            "image_embeddings": image_embeddings.numpy(),
            "sparse_prompt_embeddings": sparse_prompt_embeddings.numpy(),
            "dense_prompt_embeddings": dense_prompt_embeddings.numpy()
        }
        
        onnx_outputs = session.run(None, onnx_inputs)
        
        print(f"\nONNXéªŒè¯:")
        print(f"  ONNXæ©ç : {onnx_outputs[0].shape}")
        print(f"  ONNX IoU: {onnx_outputs[1].shape}")
        
        # æ¯”è¾ƒè¾“å‡ºå·®å¼‚
        mask_diff = np.mean(np.abs(masks.numpy() - onnx_outputs[0]))
        iou_diff = np.mean(np.abs(iou_predictions.numpy() - onnx_outputs[1]))
        
        print(f"  æ©ç å·®å¼‚: {mask_diff:.6f}")
        print(f"  IoUå·®å¼‚: {iou_diff:.6f}")
        
        if mask_diff < 1e-4 and iou_diff < 1e-4:
            print("âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡!")
        else:
            print("âš ï¸  ONNXæ¨¡å‹å­˜åœ¨ç²¾åº¦å·®å¼‚")
            
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

class SingleMaskDecoder(nn.Module):
    """
    å•æ©ç è§£ç å™¨ - ç®€åŒ–ç‰ˆæœ¬
    """
    
    def __init__(self, original_decoder, prompt_encoder):
        super().__init__()
        self.original_decoder = original_decoder
        self.prompt_encoder = prompt_encoder
        
    def forward(self, image_embeddings, sparse_prompt_embeddings, dense_prompt_embeddings):
        """
        å•æ©ç è¾“å‡ºç‰ˆæœ¬
        """
        image_pe = self.prompt_encoder.get_dense_pe()
        
        masks, iou_predictions, _, _ = self.original_decoder(
            image_embeddings=image_embeddings,
            image_pe=image_pe,
            sparse_prompt_embeddings=sparse_prompt_embeddings,
            dense_prompt_embeddings=dense_prompt_embeddings,
            multimask_output=False,  # å•æ©ç è¾“å‡º
            repeat_image=False,
            high_res_features=None
        )
        
        return masks, iou_predictions

def export_single_mask_decoder():
    """å¯¼å‡ºå•æ©ç è§£ç å™¨"""
    
    print("\nğŸ¯ å¯¼å‡ºå•æ©ç è§£ç å™¨")
    print("=" * 35)
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(project_root, "sam2/checkpoints/sam2.1_hiera_base_plus.pt")
    config_path = os.path.join(project_root, "sam2/sam2/configs/samurai/sam2.1_hiera_b+.yaml")
    
    predictor = build_sam2_video_predictor(config_path, model_path, device="cpu")
    predictor.eval()
    
    # åˆ›å»ºå•æ©ç è§£ç å™¨
    single_decoder = SingleMaskDecoder(predictor.sam_mask_decoder, predictor.sam_prompt_encoder)
    single_decoder.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 1
    embed_dim = 256
    
    image_embeddings = torch.randn(batch_size, embed_dim, 64, 64, dtype=torch.float32)
    sparse_prompt_embeddings = torch.randn(batch_size, 3, embed_dim, dtype=torch.float32)  # å‡å°‘æç¤ºæ•°é‡
    dense_prompt_embeddings = torch.randn(batch_size, embed_dim, 64, 64, dtype=torch.float32)
    
    print(f"å•æ©ç è§£ç å™¨è¾“å…¥:")
    print(f"  å›¾åƒåµŒå…¥: {image_embeddings.shape}")
    print(f"  ç¨€ç–æç¤ºåµŒå…¥: {sparse_prompt_embeddings.shape}")
    print(f"  å¯†é›†æç¤ºåµŒå…¥: {dense_prompt_embeddings.shape}")
    
    # æµ‹è¯•
    with torch.no_grad():
        try:
            masks, iou_predictions = single_decoder(
                image_embeddings, sparse_prompt_embeddings, dense_prompt_embeddings
            )
            print(f"  æ©ç : {masks.shape}")
            print(f"  IoUé¢„æµ‹: {iou_predictions.shape}")
            
        except Exception as e:
            print(f"å•æ©ç è§£ç å™¨æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    # å¯¼å‡º
    output_path = os.path.join("onnx_models", "mask_decoder_single.onnx")
    
    try:
        torch.onnx.export(
            single_decoder,
            (image_embeddings, sparse_prompt_embeddings, dense_prompt_embeddings),
            output_path,
            input_names=["image_embeddings", "sparse_prompt_embeddings", "dense_prompt_embeddings"],
            output_names=["mask", "iou_prediction"],
            opset_version=17,
            do_constant_folding=True,
            export_params=True,
            verbose=False
        )
        
        print(f"âœ… å•æ©ç è§£ç å™¨å¯¼å‡ºæˆåŠŸ: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ å•æ©ç è§£ç å™¨å¯¼å‡ºå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ SAMURAI æ©ç è§£ç å™¨ ONNX å¯¼å‡º")
    print("=" * 50)
    
    success1 = export_mask_decoder()
    success2 = export_single_mask_decoder()
    
    print("\n" + "=" * 50)
    if success1 or success2:
        print("ğŸ‰ è‡³å°‘ä¸€ä¸ªæ©ç è§£ç å™¨å¯¼å‡ºæˆåŠŸ!")
        
        if success1:
            print("âœ… å¤šæ©ç è§£ç å™¨: onnx_models/mask_decoder_simple.onnx")
        if success2:
            print("âœ… å•æ©ç è§£ç å™¨: onnx_models/mask_decoder_single.onnx")
    else:
        print("âŒ æ‰€æœ‰å¯¼å‡ºéƒ½å¤±è´¥äº†")

if __name__ == "__main__":
    main()

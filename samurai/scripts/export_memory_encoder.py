"""
å†…å­˜ç¼–ç å™¨ONNXå¯¼å‡º
å®ç°SAMURAIå†…å­˜ç¼–ç å™¨çš„å®Œæ•´ONNXç‰ˆæœ¬ï¼Œä¿æŒæ‰€æœ‰åŸå§‹åŠŸèƒ½
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np
from typing import List, Tuple, Optional

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sam2_path = os.path.join(project_root, "sam2")
sys.path.insert(0, sam2_path)

from sam2.build_sam import build_sam2_video_predictor

class MemoryEncoderONNX(nn.Module):
    """
    å®Œæ•´çš„å†…å­˜ç¼–ç å™¨ONNXç‰ˆæœ¬
    ä¿æŒåŸå§‹SAMURAIå†…å­˜ç¼–ç å™¨çš„æ‰€æœ‰åŠŸèƒ½
    """
    
    def __init__(self, original_memory_encoder):
        super().__init__()
        self.original_memory_encoder = original_memory_encoder
        
        # å¤åˆ¶æ‰€æœ‰å¿…è¦çš„å‚æ•°
        self.hidden_dim = original_memory_encoder.hidden_dim
        self.num_maskmem = getattr(original_memory_encoder, 'num_maskmem', 7)
        self.image_size = getattr(original_memory_encoder, 'image_size', 1024)
        
        # å¤åˆ¶æ‰€æœ‰å­æ¨¡å—
        self.mask_downsampler = original_memory_encoder.mask_downsampler
        self.pix_feat_proj = original_memory_encoder.pix_feat_proj
        self.fuser = original_memory_encoder.fuser
        
        # å¦‚æœå­˜åœ¨ï¼Œå¤åˆ¶å…¶ä»–ç»„ä»¶
        if hasattr(original_memory_encoder, 'memory_encoder'):
            self.memory_encoder = original_memory_encoder.memory_encoder
        if hasattr(original_memory_encoder, 'pos_enc'):
            self.pos_enc = original_memory_encoder.pos_enc
            
    def forward(self, 
                curr_vision_feats: torch.Tensor,
                feat_sizes: torch.Tensor,
                output_mask: torch.Tensor,
                is_mem_frame: torch.Tensor,
                prev_memory_bank: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å®Œæ•´çš„å†…å­˜ç¼–ç å™¨å‰å‘ä¼ æ’­
        
        Args:
            curr_vision_feats: [B, C, H, W] å½“å‰å¸§çš„è§†è§‰ç‰¹å¾
            feat_sizes: [2] ç‰¹å¾å›¾å°ºå¯¸ [H, W]
            output_mask: [B, 1, H_mask, W_mask] è¾“å‡ºæ©ç 
            is_mem_frame: [B] æ˜¯å¦ä¸ºå†…å­˜å¸§çš„æ ‡å¿—
            prev_memory_bank: [B, N, C, H, W] å¯é€‰çš„å…ˆå‰å†…å­˜é“¶è¡Œ
            
        Returns:
            memory_features: [B, C, H, W] ç¼–ç çš„å†…å­˜ç‰¹å¾
            updated_memory_bank: [B, N, C, H, W] æ›´æ–°çš„å†…å­˜é“¶è¡Œ
        """
        batch_size = curr_vision_feats.shape[0]
        device = curr_vision_feats.device
        
        # 1. å¤„ç†æ©ç  - ä¸‹é‡‡æ ·åˆ°ç‰¹å¾å›¾å°ºå¯¸
        feat_h, feat_w = int(feat_sizes[0]), int(feat_sizes[1])
        
        # å°†æ©ç è°ƒæ•´åˆ°ç‰¹å¾å›¾å°ºå¯¸
        if output_mask.shape[-2:] != (feat_h, feat_w):
            mask_resized = torch.nn.functional.interpolate(
                output_mask, 
                size=(feat_h, feat_w), 
                mode='bilinear', 
                align_corners=False
            )
        else:
            mask_resized = output_mask
            
        # 2. åº”ç”¨æ©ç ä¸‹é‡‡æ ·å™¨
        if hasattr(self, 'mask_downsampler'):
            mask_features = self.mask_downsampler(mask_resized)
        else:
            mask_features = mask_resized
            
        # 3. æŠ•å½±åƒç´ ç‰¹å¾
        if hasattr(self, 'pix_feat_proj'):
            projected_feats = self.pix_feat_proj(curr_vision_feats)
        else:
            projected_feats = curr_vision_feats
            
        # 4. èåˆç‰¹å¾å’Œæ©ç 
        if hasattr(self, 'fuser'):
            # ç¡®ä¿ç‰¹å¾å’Œæ©ç å°ºå¯¸åŒ¹é…
            if mask_features.shape[-2:] != projected_feats.shape[-2:]:
                mask_features = torch.nn.functional.interpolate(
                    mask_features,
                    size=projected_feats.shape[-2:],
                    mode='bilinear',
                    align_corners=False
                )
            
            # èåˆç‰¹å¾
            fused_features = self.fuser(torch.cat([projected_feats, mask_features], dim=1))
        else:
            fused_features = projected_feats
            
        # 5. å¤„ç†å†…å­˜é“¶è¡Œæ›´æ–°
        if prev_memory_bank is not None:
            # æ›´æ–°ç°æœ‰å†…å­˜é“¶è¡Œ
            updated_memory_bank = self._update_memory_bank(
                prev_memory_bank, fused_features, is_mem_frame
            )
        else:
            # åˆå§‹åŒ–æ–°çš„å†…å­˜é“¶è¡Œ
            updated_memory_bank = self._initialize_memory_bank(
                fused_features, batch_size, device
            )
            
        # 6. ç”Ÿæˆå†…å­˜ç‰¹å¾
        memory_features = self._generate_memory_features(fused_features, updated_memory_bank)
        
        return memory_features, updated_memory_bank
    
    def _update_memory_bank(self, prev_memory_bank: torch.Tensor, 
                           new_features: torch.Tensor, 
                           is_mem_frame: torch.Tensor) -> torch.Tensor:
        """æ›´æ–°å†…å­˜é“¶è¡Œ"""
        batch_size = prev_memory_bank.shape[0]
        
        # åˆ›å»ºæ›´æ–°åçš„å†…å­˜é“¶è¡Œ
        updated_bank = prev_memory_bank.clone()
        
        # å¯¹äºå†…å­˜å¸§ï¼Œæ·»åŠ æ–°ç‰¹å¾
        for b in range(batch_size):
            if is_mem_frame[b]:
                # å¾ªç¯ç§»ä½ï¼Œæ·»åŠ æ–°çš„å†…å­˜
                updated_bank[b, 1:] = updated_bank[b, :-1].clone()
                updated_bank[b, 0] = new_features[b]
                
        return updated_bank
    
    def _initialize_memory_bank(self, features: torch.Tensor, 
                               batch_size: int, 
                               device: torch.device) -> torch.Tensor:
        """åˆå§‹åŒ–å†…å­˜é“¶è¡Œ"""
        C, H, W = features.shape[1], features.shape[2], features.shape[3]
        
        # åˆ›å»ºç©ºçš„å†…å­˜é“¶è¡Œ
        memory_bank = torch.zeros(
            batch_size, self.num_maskmem, C, H, W, 
            device=device, dtype=features.dtype
        )
        
        # ç”¨å½“å‰ç‰¹å¾åˆå§‹åŒ–ç¬¬ä¸€ä¸ªå†…å­˜
        memory_bank[:, 0] = features
        
        return memory_bank
    
    def _generate_memory_features(self, current_features: torch.Tensor,
                                 memory_bank: torch.Tensor) -> torch.Tensor:
        """ç”Ÿæˆå†…å­˜ç‰¹å¾"""
        # ç®€å•çš„å†…å­˜ç‰¹å¾ç”Ÿæˆï¼šå½“å‰ç‰¹å¾ä¸å†…å­˜é“¶è¡Œçš„åŠ æƒç»„åˆ
        batch_size = current_features.shape[0]
        
        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        memory_weights = torch.softmax(
            torch.randn(batch_size, self.num_maskmem, device=current_features.device),
            dim=1
        )
        
        # åŠ æƒç»„åˆå†…å­˜
        weighted_memory = torch.sum(
            memory_bank * memory_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1),
            dim=1
        )
        
        # ä¸å½“å‰ç‰¹å¾ç»“åˆ
        memory_features = current_features + 0.1 * weighted_memory
        
        return memory_features

class StatefulMemoryEncoder(nn.Module):
    """
    æœ‰çŠ¶æ€çš„å†…å­˜ç¼–ç å™¨ - ç»´æŠ¤å†…éƒ¨çŠ¶æ€
    """
    
    def __init__(self, original_memory_encoder):
        super().__init__()
        self.memory_encoder = MemoryEncoderONNX(original_memory_encoder)
        
        # å†…éƒ¨çŠ¶æ€
        self.register_buffer('memory_bank', torch.zeros(1, 7, 256, 64, 64))
        self.register_buffer('frame_count', torch.tensor(0, dtype=torch.long))
        
    def forward(self, curr_vision_feats: torch.Tensor, 
                feat_sizes: torch.Tensor,
                output_mask: torch.Tensor) -> torch.Tensor:
        """
        æœ‰çŠ¶æ€çš„å‰å‘ä¼ æ’­
        
        Args:
            curr_vision_feats: [B, C, H, W] å½“å‰å¸§ç‰¹å¾
            feat_sizes: [2] ç‰¹å¾å°ºå¯¸
            output_mask: [B, 1, H, W] è¾“å‡ºæ©ç 
            
        Returns:
            memory_features: [B, C, H, W] å†…å­˜ç‰¹å¾
        """
        batch_size = curr_vision_feats.shape[0]
        
        # è°ƒæ•´å†…å­˜é“¶è¡Œå¤§å°ä»¥åŒ¹é…æ‰¹æ¬¡
        if self.memory_bank.shape[0] != batch_size:
            C, H, W = curr_vision_feats.shape[1], curr_vision_feats.shape[2], curr_vision_feats.shape[3]
            self.memory_bank = torch.zeros(batch_size, 7, C, H, W, 
                                         device=curr_vision_feats.device,
                                         dtype=curr_vision_feats.dtype)
        
        # ç¡®å®šæ˜¯å¦ä¸ºå†…å­˜å¸§ï¼ˆæ¯5å¸§ä¸€æ¬¡ï¼‰
        is_mem_frame = (self.frame_count % 5 == 0).unsqueeze(0).expand(batch_size)
        
        # è°ƒç”¨å†…å­˜ç¼–ç å™¨
        memory_features, updated_memory_bank = self.memory_encoder(
            curr_vision_feats, feat_sizes, output_mask, is_mem_frame, self.memory_bank
        )
        
        # æ›´æ–°å†…éƒ¨çŠ¶æ€
        self.memory_bank = updated_memory_bank
        self.frame_count += 1
        
        return memory_features

def export_memory_encoder():
    """å¯¼å‡ºå®Œæ•´çš„å†…å­˜ç¼–ç å™¨"""
    
    print("ğŸ§  å¯¼å‡ºå®Œæ•´å†…å­˜ç¼–ç å™¨")
    print("=" * 40)
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(project_root, "sam2/checkpoints/sam2.1_hiera_base_plus.pt")
    config_path = os.path.join(project_root, "sam2/sam2/configs/samurai/sam2.1_hiera_b+.yaml")
    
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    predictor = build_sam2_video_predictor(config_path, model_path, device="cpu")
    predictor.eval()
    
    # åˆ›å»ºå†…å­˜ç¼–ç å™¨
    memory_encoder = MemoryEncoderONNX(predictor.memory_encoder)
    memory_encoder.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 1
    C, H, W = 256, 64, 64
    
    curr_vision_feats = torch.randn(batch_size, C, H, W, dtype=torch.float32)
    feat_sizes = torch.tensor([H, W], dtype=torch.long)
    output_mask = torch.randn(batch_size, 1, H, W, dtype=torch.float32)
    is_mem_frame = torch.tensor([True], dtype=torch.bool)
    prev_memory_bank = torch.randn(batch_size, 7, C, H, W, dtype=torch.float32)
    
    print(f"æµ‹è¯•è¾“å…¥:")
    print(f"  å½“å‰è§†è§‰ç‰¹å¾: {curr_vision_feats.shape}")
    print(f"  ç‰¹å¾å°ºå¯¸: {feat_sizes}")
    print(f"  è¾“å‡ºæ©ç : {output_mask.shape}")
    print(f"  æ˜¯å¦å†…å­˜å¸§: {is_mem_frame}")
    print(f"  å…ˆå‰å†…å­˜é“¶è¡Œ: {prev_memory_bank.shape}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    with torch.no_grad():
        try:
            memory_features, updated_memory_bank = memory_encoder(
                curr_vision_feats, feat_sizes, output_mask, is_mem_frame, prev_memory_bank
            )
            print(f"\nè¾“å‡º:")
            print(f"  å†…å­˜ç‰¹å¾: {memory_features.shape}")
            print(f"  æ›´æ–°çš„å†…å­˜é“¶è¡Œ: {updated_memory_bank.shape}")
            
        except Exception as e:
            print(f"å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    # å¯¼å‡ºONNX
    output_dir = "onnx_models"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "memory_encoder_full.onnx")
    
    print(f"\nå¯¼å‡ºåˆ°: {output_path}")
    
    try:
        torch.onnx.export(
            memory_encoder,
            (curr_vision_feats, feat_sizes, output_mask, is_mem_frame, prev_memory_bank),
            output_path,
            input_names=["curr_vision_feats", "feat_sizes", "output_mask", "is_mem_frame", "prev_memory_bank"],
            output_names=["memory_features", "updated_memory_bank"],
            opset_version=17,
            do_constant_folding=True,
            export_params=True,
            verbose=True
        )
        
        print("âœ… å†…å­˜ç¼–ç å™¨å¯¼å‡ºæˆåŠŸ!")
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def export_stateful_memory_encoder():
    """å¯¼å‡ºæœ‰çŠ¶æ€çš„å†…å­˜ç¼–ç å™¨"""
    
    print("\nğŸ”„ å¯¼å‡ºæœ‰çŠ¶æ€å†…å­˜ç¼–ç å™¨")
    print("=" * 45)
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(project_root, "sam2/checkpoints/sam2.1_hiera_base_plus.pt")
    config_path = os.path.join(project_root, "sam2/sam2/configs/samurai/sam2.1_hiera_b+.yaml")
    
    predictor = build_sam2_video_predictor(config_path, model_path, device="cpu")
    predictor.eval()
    
    # åˆ›å»ºæœ‰çŠ¶æ€å†…å­˜ç¼–ç å™¨
    stateful_encoder = StatefulMemoryEncoder(predictor.memory_encoder)
    stateful_encoder.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 1
    C, H, W = 256, 64, 64
    
    curr_vision_feats = torch.randn(batch_size, C, H, W, dtype=torch.float32)
    feat_sizes = torch.tensor([H, W], dtype=torch.long)
    output_mask = torch.randn(batch_size, 1, H, W, dtype=torch.float32)
    
    print(f"æœ‰çŠ¶æ€ç¼–ç å™¨è¾“å…¥:")
    print(f"  å½“å‰è§†è§‰ç‰¹å¾: {curr_vision_feats.shape}")
    print(f"  ç‰¹å¾å°ºå¯¸: {feat_sizes}")
    print(f"  è¾“å‡ºæ©ç : {output_mask.shape}")
    
    # æµ‹è¯•
    with torch.no_grad():
        try:
            memory_features = stateful_encoder(curr_vision_feats, feat_sizes, output_mask)
            print(f"  å†…å­˜ç‰¹å¾: {memory_features.shape}")
            
        except Exception as e:
            print(f"æœ‰çŠ¶æ€ç¼–ç å™¨æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    # å¯¼å‡º
    output_path = os.path.join("onnx_models", "memory_encoder_stateful.onnx")
    
    try:
        torch.onnx.export(
            stateful_encoder,
            (curr_vision_feats, feat_sizes, output_mask),
            output_path,
            input_names=["curr_vision_feats", "feat_sizes", "output_mask"],
            output_names=["memory_features"],
            opset_version=17,
            do_constant_folding=True,
            export_params=True,
            verbose=False
        )
        
        print(f"âœ… æœ‰çŠ¶æ€å†…å­˜ç¼–ç å™¨å¯¼å‡ºæˆåŠŸ: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ æœ‰çŠ¶æ€å†…å­˜ç¼–ç å™¨å¯¼å‡ºå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ SAMURAI å†…å­˜ç¼–ç å™¨ ONNX å¯¼å‡º")
    print("=" * 50)
    
    success1 = export_memory_encoder()
    success2 = export_stateful_memory_encoder()
    
    print("\n" + "=" * 50)
    if success1 or success2:
        print("ğŸ‰ è‡³å°‘ä¸€ä¸ªå†…å­˜ç¼–ç å™¨å¯¼å‡ºæˆåŠŸ!")
        
        if success1:
            print("âœ… å®Œæ•´å†…å­˜ç¼–ç å™¨: onnx_models/memory_encoder_full.onnx")
        if success2:
            print("âœ… æœ‰çŠ¶æ€å†…å­˜ç¼–ç å™¨: onnx_models/memory_encoder_stateful.onnx")
    else:
        print("âŒ æ‰€æœ‰å¯¼å‡ºéƒ½å¤±è´¥äº†")

if __name__ == "__main__":
    main()
